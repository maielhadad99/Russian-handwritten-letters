{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Russian handwritten letters.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0AaMAedwsxoJ7WZwHoRjC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maielhadad99/Russian-handwritten-letters/blob/main/Russian_handwritten_letters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ick0vnW5I2ey"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv(\"/content/Input/letters.csv\")\n",
        "df1.head()\n",
        "files1=df1['file']\n",
        "letters1=df1[\"letter\"]\n",
        "backgrounds1=df1['background']"
      ],
      "metadata": {
        "id": "NoIVVm9CLlcW"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2=pd.read_csv(\"/content/Input/letters2.csv\")\n",
        "files2=df2['file']\n",
        "letters2=df2[\"letter\"]\n",
        "backgrounds2=df2['background']"
      ],
      "metadata": {
        "id": "KwE1gbpSLlaL"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3=pd.read_csv(\"/content/Input/letters3.csv\")\n",
        "files3=df3['file']\n",
        "letters3=df3[\"letter\"]\n",
        "backgrounds3=df3['background']"
      ],
      "metadata": {
        "id": "_Te6YJ_iLlXw"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "f = h5py.File(\"/content/Input/LetterColorImages_123.h5\",'r')\n",
        "keys = list(f.keys())\n",
        "keys"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69ACC13uLlVE",
        "outputId": "3bc5ee29-4183-404b-c74b-84ba7bba57d1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['backgrounds', 'images', 'labels']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backgrounds = np.array(f[keys[0]])\n",
        "tensors = images = np.array(f[keys[1]])\n",
        "targets = np.array(f[keys[2]])\n",
        "print ('Tensor shape:', tensors.shape)\n",
        "print ('Target shape', targets.shape)\n",
        "print ('Background shape:', backgrounds.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkHAp3BJLlP4",
        "outputId": "a90d81b6-f276-440e-bd55-2482e5d6ef91"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor shape: (14190, 32, 32, 3)\n",
            "Target shape (14190,)\n",
            "Background shape: (14190,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "letters = pd.concat((df1,df2),axis= 0,ignore_index=True)\n",
        "letters = pd.concat((letters,df3),axis = 0 , ignore_index=True)\n",
        "letters.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ecia0etaLlNP",
        "outputId": "15b18bbb-fdd0-4721-abb6-331b4261cd0e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a0c4763e-62f4-40e1-bdb3-4fa47209fd08\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>letter</th>\n",
              "      <th>label</th>\n",
              "      <th>file</th>\n",
              "      <th>background</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>а</td>\n",
              "      <td>1</td>\n",
              "      <td>01_01.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>а</td>\n",
              "      <td>1</td>\n",
              "      <td>01_02.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>а</td>\n",
              "      <td>1</td>\n",
              "      <td>01_03.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>а</td>\n",
              "      <td>1</td>\n",
              "      <td>01_04.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>а</td>\n",
              "      <td>1</td>\n",
              "      <td>01_05.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0c4763e-62f4-40e1-bdb3-4fa47209fd08')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a0c4763e-62f4-40e1-bdb3-4fa47209fd08 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a0c4763e-62f4-40e1-bdb3-4fa47209fd08');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  letter  label       file  background\n",
              "0      а      1  01_01.png           0\n",
              "1      а      1  01_02.png           0\n",
              "2      а      1  01_03.png           0\n",
              "3      а      1  01_04.png           0\n",
              "4      а      1  01_05.png           0"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(letters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPFZ5I_yLlKv",
        "outputId": "51732a8f-ad1e-4522-d847-001ed943fd84"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14190"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensors = tensors.astype('float32')/255"
      ],
      "metadata": {
        "id": "YAuV4XGrLlIS"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "from matplotlib import cm\n",
        "%matplotlib inline\n",
        "\n",
        "# Read and display a tensor using Matplotlib\n",
        "plt.figure(figsize=(3,3))\n",
        "plt.imshow(tensors[10]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "BLdTaa7GLlFy",
        "outputId": "34c39688-f725-400c-9dc7-8d8092a84a85"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 216x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(targets))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBUVmRInLlAh",
        "outputId": "192495d0-0809-4bc3-af8e-1dc4bbd06b0f"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dldozak2dhjT",
        "outputId": "f07a2d3b-7134-4f23-affa-32aa339764a5"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# One-hot encoding the targets, started from the zero label\n",
        "cat_targets = to_categorical(np.array(targets-1), 33)\n",
        "cat_targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj_4hc5PLk92",
        "outputId": "fe7bbc88-8108-4868-cc7e-6d4a87fa070e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14190, 33)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(tensors, cat_targets,test_size = 0.2,random_state = 1)\n",
        "                                                     \n",
        "                                                    \n",
        "n = int(len(x_test)/2)\n",
        "x_valid, y_valid = x_test[:n], y_test[:n]\n",
        "x_test, y_test = x_test[n:], y_test[n:]\n",
        "\n",
        "# Print the shape\n",
        "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape, x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLastohQLk1F",
        "outputId": "c26a753f-c993-4f5b-ca73-8c461ae2e151"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11352, 32, 32, 3),\n",
              " (11352, 33),\n",
              " (1419, 32, 32, 3),\n",
              " (1419, 33),\n",
              " (1419, 32, 32, 3),\n",
              " (1419, 33))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import image as keras_image\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.metrics import top_k_categorical_accuracy, categorical_accuracy\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
        "from keras.layers.advanced_activations import PReLU, LeakyReLU\n",
        "from keras.layers import Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "\n",
        "def top_3_categorical_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Define a model architecture    \n",
        "model.add(Conv2D(32, (5, 5), padding='same', input_shape=x_train.shape[1:]))\n",
        "model.add(LeakyReLU(alpha=0.02))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(192, (5, 5)))\n",
        "model.add(LeakyReLU(alpha=0.02))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(GlobalMaxPooling2D())\n",
        "\n",
        "model.add(Dense(1024))\n",
        "model.add(LeakyReLU(alpha=0.02))\n",
        "model.add(Dropout(0.5)) \n",
        "\n",
        "model.add(Dense(33))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "              metrics=[categorical_accuracy, top_3_categorical_accuracy])"
      ],
      "metadata": {
        "id": "fhU7o8RIfZXS"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpointer = ModelCheckpoint(filepath='weights.best.model.hdf5', verbose=2, save_best_only=True)\n",
        "lr_reduction = ReduceLROnPlateau(monitor='val_loss', patience=5, verbose=2, factor=0.75)\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=50, batch_size=512, verbose=2,validation_data=(x_valid, y_valid),callbacks=[checkpointer, lr_reduction])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU1hz5GGfZMN",
        "outputId": "7a4d16e4-9a1d-4630-8803-c8fd2b8c087f"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 3.48263, saving model to weights.best.model.hdf5\n",
            "23/23 - 41s - loss: 3.4920 - categorical_accuracy: 0.0324 - top_3_categorical_accuracy: 0.0969 - val_loss: 3.4826 - val_categorical_accuracy: 0.0240 - val_top_3_categorical_accuracy: 0.0951 - lr: 0.0010 - 41s/epoch - 2s/step\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: val_loss improved from 3.48263 to 3.44543, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 3.4628 - categorical_accuracy: 0.0425 - top_3_categorical_accuracy: 0.1195 - val_loss: 3.4454 - val_categorical_accuracy: 0.0557 - val_top_3_categorical_accuracy: 0.1656 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.44543 to 3.34845, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 3.3959 - categorical_accuracy: 0.0638 - top_3_categorical_accuracy: 0.1649 - val_loss: 3.3485 - val_categorical_accuracy: 0.0860 - val_top_3_categorical_accuracy: 0.2276 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.34845 to 3.27705, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 3.3077 - categorical_accuracy: 0.0719 - top_3_categorical_accuracy: 0.1986 - val_loss: 3.2771 - val_categorical_accuracy: 0.0796 - val_top_3_categorical_accuracy: 0.2290 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.27705 to 3.22413, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 3.2192 - categorical_accuracy: 0.0844 - top_3_categorical_accuracy: 0.2250 - val_loss: 3.2241 - val_categorical_accuracy: 0.0895 - val_top_3_categorical_accuracy: 0.2544 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.22413 to 3.12859, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 3.1551 - categorical_accuracy: 0.0930 - top_3_categorical_accuracy: 0.2486 - val_loss: 3.1286 - val_categorical_accuracy: 0.1057 - val_top_3_categorical_accuracy: 0.2565 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: val_loss improved from 3.12859 to 3.10036, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 3.1432 - categorical_accuracy: 0.0958 - top_3_categorical_accuracy: 0.2584 - val_loss: 3.1004 - val_categorical_accuracy: 0.0958 - val_top_3_categorical_accuracy: 0.2819 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.10036 to 3.02310, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 3.0519 - categorical_accuracy: 0.1122 - top_3_categorical_accuracy: 0.2835 - val_loss: 3.0231 - val_categorical_accuracy: 0.1367 - val_top_3_categorical_accuracy: 0.3369 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: val_loss improved from 3.02310 to 2.93124, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 2.9793 - categorical_accuracy: 0.1277 - top_3_categorical_accuracy: 0.3102 - val_loss: 2.9312 - val_categorical_accuracy: 0.1727 - val_top_3_categorical_accuracy: 0.3918 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.93124 to 2.84277, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 2.8835 - categorical_accuracy: 0.1537 - top_3_categorical_accuracy: 0.3602 - val_loss: 2.8428 - val_categorical_accuracy: 0.1811 - val_top_3_categorical_accuracy: 0.4165 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: val_loss improved from 2.84277 to 2.64485, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 2.7266 - categorical_accuracy: 0.1979 - top_3_categorical_accuracy: 0.4321 - val_loss: 2.6448 - val_categorical_accuracy: 0.2488 - val_top_3_categorical_accuracy: 0.5187 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.64485 to 2.48955, saving model to weights.best.model.hdf5\n",
            "23/23 - 40s - loss: 2.5632 - categorical_accuracy: 0.2400 - top_3_categorical_accuracy: 0.4874 - val_loss: 2.4896 - val_categorical_accuracy: 0.2650 - val_top_3_categorical_accuracy: 0.5363 - lr: 0.0010 - 40s/epoch - 2s/step\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: val_loss improved from 2.48955 to 2.27914, saving model to weights.best.model.hdf5\n",
            "23/23 - 40s - loss: 2.4017 - categorical_accuracy: 0.2757 - top_3_categorical_accuracy: 0.5420 - val_loss: 2.2791 - val_categorical_accuracy: 0.3686 - val_top_3_categorical_accuracy: 0.6237 - lr: 0.0010 - 40s/epoch - 2s/step\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.27914\n",
            "23/23 - 39s - loss: 2.2360 - categorical_accuracy: 0.3251 - top_3_categorical_accuracy: 0.5931 - val_loss: 2.3010 - val_categorical_accuracy: 0.3242 - val_top_3_categorical_accuracy: 0.5751 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: val_loss improved from 2.27914 to 2.01342, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 2.1559 - categorical_accuracy: 0.3511 - top_3_categorical_accuracy: 0.6174 - val_loss: 2.0134 - val_categorical_accuracy: 0.4228 - val_top_3_categorical_accuracy: 0.6836 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: val_loss improved from 2.01342 to 1.87834, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 1.9611 - categorical_accuracy: 0.4092 - top_3_categorical_accuracy: 0.6786 - val_loss: 1.8783 - val_categorical_accuracy: 0.4870 - val_top_3_categorical_accuracy: 0.7273 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.87834 to 1.71160, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 1.8389 - categorical_accuracy: 0.4487 - top_3_categorical_accuracy: 0.7119 - val_loss: 1.7116 - val_categorical_accuracy: 0.5638 - val_top_3_categorical_accuracy: 0.7787 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.71160 to 1.62860, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 1.7352 - categorical_accuracy: 0.4804 - top_3_categorical_accuracy: 0.7331 - val_loss: 1.6286 - val_categorical_accuracy: 0.5638 - val_top_3_categorical_accuracy: 0.7956 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: val_loss improved from 1.62860 to 1.53399, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 1.6266 - categorical_accuracy: 0.5126 - top_3_categorical_accuracy: 0.7616 - val_loss: 1.5340 - val_categorical_accuracy: 0.5955 - val_top_3_categorical_accuracy: 0.8055 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: val_loss improved from 1.53399 to 1.49804, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 1.5644 - categorical_accuracy: 0.5332 - top_3_categorical_accuracy: 0.7776 - val_loss: 1.4980 - val_categorical_accuracy: 0.5920 - val_top_3_categorical_accuracy: 0.8111 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: val_loss improved from 1.49804 to 1.36132, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 1.4838 - categorical_accuracy: 0.5534 - top_3_categorical_accuracy: 0.7916 - val_loss: 1.3613 - val_categorical_accuracy: 0.6448 - val_top_3_categorical_accuracy: 0.8443 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: val_loss improved from 1.36132 to 1.29260, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 1.4054 - categorical_accuracy: 0.5822 - top_3_categorical_accuracy: 0.8118 - val_loss: 1.2926 - val_categorical_accuracy: 0.6667 - val_top_3_categorical_accuracy: 0.8513 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: val_loss improved from 1.29260 to 1.24158, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 1.3562 - categorical_accuracy: 0.5928 - top_3_categorical_accuracy: 0.8211 - val_loss: 1.2416 - val_categorical_accuracy: 0.6984 - val_top_3_categorical_accuracy: 0.8548 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.24158\n",
            "23/23 - 38s - loss: 1.2894 - categorical_accuracy: 0.6100 - top_3_categorical_accuracy: 0.8322 - val_loss: 1.2540 - val_categorical_accuracy: 0.6730 - val_top_3_categorical_accuracy: 0.8541 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: val_loss improved from 1.24158 to 1.12815, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 1.2569 - categorical_accuracy: 0.6143 - top_3_categorical_accuracy: 0.8433 - val_loss: 1.1282 - val_categorical_accuracy: 0.7259 - val_top_3_categorical_accuracy: 0.8837 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.12815\n",
            "23/23 - 38s - loss: 1.2099 - categorical_accuracy: 0.6369 - top_3_categorical_accuracy: 0.8506 - val_loss: 1.1626 - val_categorical_accuracy: 0.6934 - val_top_3_categorical_accuracy: 0.8661 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: val_loss improved from 1.12815 to 1.09822, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 1.1717 - categorical_accuracy: 0.6485 - top_3_categorical_accuracy: 0.8569 - val_loss: 1.0982 - val_categorical_accuracy: 0.7216 - val_top_3_categorical_accuracy: 0.8732 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: val_loss improved from 1.09822 to 1.00501, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 1.1143 - categorical_accuracy: 0.6588 - top_3_categorical_accuracy: 0.8673 - val_loss: 1.0050 - val_categorical_accuracy: 0.7498 - val_top_3_categorical_accuracy: 0.8858 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: val_loss improved from 1.00501 to 0.99190, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 1.0850 - categorical_accuracy: 0.6685 - top_3_categorical_accuracy: 0.8728 - val_loss: 0.9919 - val_categorical_accuracy: 0.7393 - val_top_3_categorical_accuracy: 0.8929 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.99190\n",
            "23/23 - 39s - loss: 1.0459 - categorical_accuracy: 0.6819 - top_3_categorical_accuracy: 0.8789 - val_loss: 1.0294 - val_categorical_accuracy: 0.7174 - val_top_3_categorical_accuracy: 0.8823 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.99190\n",
            "23/23 - 39s - loss: 1.0653 - categorical_accuracy: 0.6764 - top_3_categorical_accuracy: 0.8727 - val_loss: 1.0140 - val_categorical_accuracy: 0.7202 - val_top_3_categorical_accuracy: 0.8872 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: val_loss improved from 0.99190 to 0.95286, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 1.0385 - categorical_accuracy: 0.6826 - top_3_categorical_accuracy: 0.8809 - val_loss: 0.9529 - val_categorical_accuracy: 0.7428 - val_top_3_categorical_accuracy: 0.8922 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: val_loss improved from 0.95286 to 0.85871, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 0.9896 - categorical_accuracy: 0.7005 - top_3_categorical_accuracy: 0.8869 - val_loss: 0.8587 - val_categorical_accuracy: 0.7731 - val_top_3_categorical_accuracy: 0.9098 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.85871\n",
            "23/23 - 39s - loss: 0.9462 - categorical_accuracy: 0.7118 - top_3_categorical_accuracy: 0.8937 - val_loss: 0.8854 - val_categorical_accuracy: 0.7555 - val_top_3_categorical_accuracy: 0.8978 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.85871 to 0.79244, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 0.9179 - categorical_accuracy: 0.7210 - top_3_categorical_accuracy: 0.8968 - val_loss: 0.7924 - val_categorical_accuracy: 0.7977 - val_top_3_categorical_accuracy: 0.9232 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: val_loss improved from 0.79244 to 0.77533, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.8843 - categorical_accuracy: 0.7323 - top_3_categorical_accuracy: 0.9032 - val_loss: 0.7753 - val_categorical_accuracy: 0.7977 - val_top_3_categorical_accuracy: 0.9253 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: val_loss improved from 0.77533 to 0.75007, saving model to weights.best.model.hdf5\n",
            "23/23 - 39s - loss: 0.8605 - categorical_accuracy: 0.7365 - top_3_categorical_accuracy: 0.9086 - val_loss: 0.7501 - val_categorical_accuracy: 0.8069 - val_top_3_categorical_accuracy: 0.9274 - lr: 0.0010 - 39s/epoch - 2s/step\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: val_loss improved from 0.75007 to 0.73690, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.8455 - categorical_accuracy: 0.7447 - top_3_categorical_accuracy: 0.9064 - val_loss: 0.7369 - val_categorical_accuracy: 0.8076 - val_top_3_categorical_accuracy: 0.9260 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.73690\n",
            "23/23 - 38s - loss: 0.8157 - categorical_accuracy: 0.7522 - top_3_categorical_accuracy: 0.9142 - val_loss: 0.7726 - val_categorical_accuracy: 0.7921 - val_top_3_categorical_accuracy: 0.9204 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.73690\n",
            "23/23 - 38s - loss: 0.8197 - categorical_accuracy: 0.7495 - top_3_categorical_accuracy: 0.9145 - val_loss: 0.7548 - val_categorical_accuracy: 0.8055 - val_top_3_categorical_accuracy: 0.9331 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.73690\n",
            "23/23 - 38s - loss: 0.7801 - categorical_accuracy: 0.7630 - top_3_categorical_accuracy: 0.9207 - val_loss: 0.7981 - val_categorical_accuracy: 0.7710 - val_top_3_categorical_accuracy: 0.9225 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: val_loss improved from 0.73690 to 0.67048, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.7544 - categorical_accuracy: 0.7711 - top_3_categorical_accuracy: 0.9242 - val_loss: 0.6705 - val_categorical_accuracy: 0.8288 - val_top_3_categorical_accuracy: 0.9338 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: val_loss improved from 0.67048 to 0.66996, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.7353 - categorical_accuracy: 0.7782 - top_3_categorical_accuracy: 0.9257 - val_loss: 0.6700 - val_categorical_accuracy: 0.8203 - val_top_3_categorical_accuracy: 0.9359 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.66996 to 0.65301, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.7236 - categorical_accuracy: 0.7796 - top_3_categorical_accuracy: 0.9272 - val_loss: 0.6530 - val_categorical_accuracy: 0.8245 - val_top_3_categorical_accuracy: 0.9338 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: val_loss improved from 0.65301 to 0.63868, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.7053 - categorical_accuracy: 0.7869 - top_3_categorical_accuracy: 0.9310 - val_loss: 0.6387 - val_categorical_accuracy: 0.8330 - val_top_3_categorical_accuracy: 0.9359 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.63868 to 0.63522, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.6999 - categorical_accuracy: 0.7891 - top_3_categorical_accuracy: 0.9301 - val_loss: 0.6352 - val_categorical_accuracy: 0.8210 - val_top_3_categorical_accuracy: 0.9373 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.63522 to 0.62318, saving model to weights.best.model.hdf5\n",
            "23/23 - 37s - loss: 0.6763 - categorical_accuracy: 0.7948 - top_3_categorical_accuracy: 0.9338 - val_loss: 0.6232 - val_categorical_accuracy: 0.8316 - val_top_3_categorical_accuracy: 0.9401 - lr: 0.0010 - 37s/epoch - 2s/step\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.62318 to 0.62241, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.6720 - categorical_accuracy: 0.7935 - top_3_categorical_accuracy: 0.9359 - val_loss: 0.6224 - val_categorical_accuracy: 0.8344 - val_top_3_categorical_accuracy: 0.9373 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.62241 to 0.61557, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.6608 - categorical_accuracy: 0.7986 - top_3_categorical_accuracy: 0.9372 - val_loss: 0.6156 - val_categorical_accuracy: 0.8302 - val_top_3_categorical_accuracy: 0.9415 - lr: 0.0010 - 38s/epoch - 2s/step\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.61557 to 0.58876, saving model to weights.best.model.hdf5\n",
            "23/23 - 38s - loss: 0.6542 - categorical_accuracy: 0.8000 - top_3_categorical_accuracy: 0.9394 - val_loss: 0.5888 - val_categorical_accuracy: 0.8393 - val_top_3_categorical_accuracy: 0.9387 - lr: 0.0010 - 38s/epoch - 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
        "pred"
      ],
      "metadata": {
        "id": "X5zDLD2wfZD9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}